# AFURI èœå•çˆ¬å–ä¸æœç´¢ç³»ç»Ÿ

ä» AFURI ç½‘ç«™çˆ¬å–èœå•æ•°æ®ï¼Œè¿›è¡Œæ¸…ç†å’Œç´¢å¼•ï¼Œæä¾›å‰ç«¯æœç´¢ç•Œé¢ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip3 install -r requirements.txt
```

### 2. è¿è¡Œå®Œæ•´æµç¨‹

```bash
# è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆçˆ¬å– -> æ¸…ç† -> ç´¢å¼•ï¼‰
python3 run_pipeline.py

# å¦‚æœ Solr æœªè¿è¡Œï¼Œè·³è¿‡ç´¢å¼•æ­¥éª¤
python3 run_pipeline.py --skip-index

# è¿è¡Œå¹¶å¯åŠ¨å‰ç«¯æœåŠ¡
python3 run_pipeline.py --start-frontend
```

### 3. ä½¿ç”¨å‰ç«¯ç•Œé¢

```bash
# å¯åŠ¨å‰ç«¯æœåŠ¡å™¨
bash start_frontend.sh
# æˆ–
python3 -m http.server 8000
```

åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼š**http://localhost:8000/frontend/**

## ğŸ“– åŠŸèƒ½è¯´æ˜

### æ•°æ®å¤„ç†æµç¨‹

1. **çˆ¬å–** - ä» AFURI ç½‘ç«™çˆ¬å–èœå•ã€åº—é“ºå’Œå“ç‰Œä¿¡æ¯
2. **æ¸…ç†** - æ¸…ç†å’Œè§„èŒƒåŒ–æ•°æ®ï¼Œç§»é™¤é‡å¤é¡¹
3. **ç´¢å¼•** - å°†æ•°æ®ç´¢å¼•åˆ° Solrï¼ˆå¯é€‰ï¼‰
4. **æœç´¢** - é€šè¿‡å‰ç«¯ç•Œé¢æœç´¢å’Œæµè§ˆ

### æœç´¢æ¨¡å¼

- **æœ¬åœ°æœç´¢**ï¼šç›´æ¥æœç´¢ JSON æ–‡ä»¶ï¼Œæ— éœ€ Solr
- **Solr æœç´¢**ï¼šä½¿ç”¨ Solr æä¾›æ›´å¼ºå¤§çš„æœç´¢åŠŸèƒ½ï¼ˆéœ€è¦å®‰è£… Solrï¼‰

## ğŸ”§ Solr è®¾ç½®ï¼ˆå¯é€‰ï¼‰

### å®‰è£…å’Œå¯åŠ¨

```bash
# macOS
brew install solr
solr start
solr create -c afuri_menu

# Linux
wget https://archive.apache.org/dist/solr/solr/8.11.2/solr-8.11.2.tgz
tar xzf solr-8.11.2.tgz
cd solr-8.11.2
./bin/solr start
./bin/solr create -c afuri_menu
```

### ç´¢å¼•æ•°æ®

```bash
python3 run_pipeline.py
# æˆ–åªæ‰§è¡Œç´¢å¼•
python3 run_pipeline.py --skip-scrape --skip-clean
```

### Solr çš„ä¼˜åŠ¿

- âš¡ **å¿«é€Ÿæœç´¢** - ç´¢å¼•ä¼˜åŒ–ï¼Œæ¯«ç§’çº§å“åº”
- ğŸ¯ **æ™ºèƒ½æ’åº** - ç›¸å…³æ€§è¯„åˆ†ï¼Œæœ€ç›¸å…³çš„ç»“æœåœ¨å‰
- ğŸ” **å¤æ‚æŸ¥è¯¢** - æ”¯æŒå¸ƒå°”æŸ¥è¯¢ã€çŸ­è¯­æœç´¢ç­‰
- ğŸ“Š **é«˜çº§åŠŸèƒ½** - åˆ†é¢æœç´¢ã€é«˜äº®æ˜¾ç¤ºã€ç»Ÿè®¡åˆ†æ

## ğŸ“ é¡¹ç›®ç»“æ„

```
Information_Retrieval/
â”œâ”€â”€ run_pipeline.py          # ä¸»æµç¨‹è„šæœ¬
â”œâ”€â”€ scraper.py               # çˆ¬å–æ¨¡å—
â”œâ”€â”€ data_cleaner.py          # æ¸…ç†æ¨¡å—
â”œâ”€â”€ solr_indexer.py          # ç´¢å¼•æ¨¡å—
â”œâ”€â”€ solr_proxy.py            # Solr ä»£ç†æœåŠ¡å™¨
â”œâ”€â”€ start_frontend.sh        # å‰ç«¯å¯åŠ¨è„šæœ¬
â”œâ”€â”€ frontend/                # å‰ç«¯ç•Œé¢
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ styles.css
â”‚   â””â”€â”€ app.js
â””â”€â”€ data/                    # æ•°æ®ç›®å½•
    â”œâ”€â”€ scraped_data.json    # åŸå§‹æ•°æ®
    â””â”€â”€ cleaned_data.json    # æ¸…ç†åæ•°æ®
```

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤

```bash
# è¿è¡Œå®Œæ•´æµç¨‹
python3 run_pipeline.py

# åªæ‰§è¡Œçˆ¬å–å’Œæ¸…ç†
python3 run_pipeline.py --skip-index

# åªæ‰§è¡Œç´¢å¼•
python3 run_pipeline.py --skip-scrape --skip-clean

# æ£€æŸ¥ Solr çŠ¶æ€
solr status

# æŸ¥çœ‹æ•°æ®ç»Ÿè®¡
python3 -c "import json; data = json.load(open('data/cleaned_data.json')); print(f'å…± {len(data)} ä¸ªèœå•é¡¹')"
```

## â“ æ•…éšœæ’é™¤

### é—®é¢˜ï¼šæ‰¾ä¸åˆ°æ¨¡å—
```bash
pip3 install -r requirements.txt
```

### é—®é¢˜ï¼šæ— æ³•è®¿é—®ç½‘ç«™
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- ç¡®è®¤ https://afuri.com/menu/ å¯ä»¥è®¿é—®

### é—®é¢˜ï¼šSolr è¿æ¥å¤±è´¥
- ç¡®è®¤ Solr æ­£åœ¨è¿è¡Œï¼š`solr status`
- ç¡®è®¤æ ¸å¿ƒå·²åˆ›å»ºï¼š`solr create -c afuri_menu`
- æ£€æŸ¥ç«¯å£ 8983 æ˜¯å¦è¢«å ç”¨

### é—®é¢˜ï¼šå‰ç«¯æ— æ³•åŠ è½½æ•°æ®
- ç¡®è®¤å·²è¿è¡Œ `python3 run_pipeline.py`
- ç¡®è®¤ `data/cleaned_data.json` æ–‡ä»¶å­˜åœ¨
- æ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°æ˜¯å¦æœ‰é”™è¯¯

## ğŸ“Š æ•°æ®æ ¼å¼

æ¯ä¸ªèœå•é¡¹åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{
  "url": "https://afuri.com/menu/",
  "title": "Menu - Yuzu Shio Ramen",
  "content": "èœå•æè¿°...",
  "section": "Menu",
  "menu_item": "Yuzu Shio Ramen",
  "menu_category": "Ramen",
  "ingredients": "chicken & dashi based broth, yuzu..."
}
```

**åˆ†ç±»**ï¼šRamen, Noodles, Side Dishes, Drinks, Chi-yu

## ğŸ“ æ³¨æ„äº‹é¡¹

- æ•°æ®ä½¿ç”¨ UTF-8 ç¼–ç ï¼Œæ”¯æŒæ—¥æ–‡å­—ç¬¦
- è„šæœ¬ä¼šè‡ªåŠ¨åˆ›å»º `data/` ç›®å½•
- èœå•é¡¹ä¼šè‡ªåŠ¨åˆ†ç±»
- Solr æ˜¯å¯é€‰çš„ï¼Œæœ¬åœ°æœç´¢ä¹Ÿå¯ä»¥æ­£å¸¸å·¥ä½œ

---

**æœ€åæ›´æ–°**ï¼š2025
